Continue..

Spark SQL higher-order functions:

---
(43) aggregate function set calculated value in a struct field of accumulator
  REF: https://stackoverflow.com/q/65515349/9510729
  Issue: any null elements in the `col` array will result in the null value for the whole calculation
    using the below aggregate function, to overcome this we need to use coalesce while reset size of the
    array elements to exclude null:

    from pyspark.sql import functions as func

  Not working:

    power_mean = lambda col: func.expr(f"""
        aggregate(`{col}`, 0D, (acc,x) -> acc+power(x, 2*size(`{col}`)), acc -> power(acc/size(`{col}`),0.5/size(`{col}`)))
    """)

  Working solution:
    
    power_mean = lambda col: func.expr(f"""
        aggregate(
            /* expr: array column to iterate through */
            `{col}`,
            /* start: set zero value and accumulator as an struct<psum:double,n:int> */
            (0D as psum, size(filter(`{col}`, x -> x is not null)) as n),
            /* merge: iterate through expr and calculate `sum([(x)**p for x in values])` */
            (acc,x) -> named_struct(
                    "psum", acc.psum + power(coalesce(x,0), 2*acc.n), 
                    "n", acc.n
                ),
            /* finish: post processing */
            acc -> power(acc.psum/acc.n, 0.5/acc.n)
        )
    """)
    
    df = spark.createDataFrame([([20,5,None,10],)],['value'])
    df.select("value", power_mean("value").alias('totalScore')).show(truncate=False)
    +------------+------------------+
    |value       |totalScore        |
    +------------+------------------+
    |[20, 5,, 10]|16.697421658984894|
    +------------+------------------+
    
  Note: for Spark 3.4.0+, using array_compact() function can remove all nulls from the array which makes things 
        simpler:

    power_mean = lambda col: func.expr(f"""
        aggregate(
            array_compact(`{col}`),
            (0D as psum, size(`{col}`) as n),
            (acc,x) -> (acc.psum+power(x,2*acc.n) as psum, acc.n as n),
            acc -> power(acc.psum/acc.n, 0.5/acc.n)
         )
    """)



(44) discard all elements after one matches from the stop-words
  Method: using aggregate function, set a flag and skip the elements when it becomes true

    from pyspark.sql import functions as F

    df = spark.createDataFrame([
      ("Variable speeds allow you to refine every texture with culinary precision",),
      ("Perfect for family meals and entertaining and kitchen cabinets",),
      ("The more research you do, the more questions you may have",),
    ], ['value'])

    stop_words = ["and", "you"]

    df.selectExpr("flatten(sentences(lower(value))) as words") \
        .withColumn('stop_words', F.lit(stop_words)) \
        .selectExpr("words", """
            aggregate(
                words, 
                cast((array(), false) as struct<words:array<string>,flag:boolean>),
                (acc,x) -> CASE WHEN acc.flag THEN acc
                        WHEN array_contains(stop_words, x) THEN named_struct("words", acc.words, "flag", true)
                        ELSE named_struct("words", array_append(acc.words, x), "flag", false)
                    END,
                acc -> acc.words
            ) as cleaned_words
         """).show(truncate=False)
    +-------------------------------------------------------------------------------------+-----------------------------+
    |words                                                                                |cleaned_words                |
    +-------------------------------------------------------------------------------------+-----------------------------+
    |[variable, speeds, allow, you, to, refine, every, texture, with, culinary, precision]|[variable, speeds, allow]    |
    |[perfect, for, family, meals, and, entertaining, and, kitchen, cabinets]             |[perfect, for, family, meals]|
    |[the, more, research, you, do, the, more, questions, you, may, have]                 |[the, more, research]        |
    +-------------------------------------------------------------------------------------+-----------------------------+

  Note:
   (1) array() is an EMPTY array, so there is no need to remove the first element on the finish argument (skipped it)
   (2) Another way using regexp_replace:

       # stop words by default split by white-spaces, escape metacharacters
       ptn = '(^|\s+)(?:{})(\s+|$).*'.format('|'.join(stop_words))

       df.withColumn('value', F.regexp_replace(F.lower(F.col('value')), ptn, '')) \
           .selectExpr('flatten(sentences(value)) as words') \
           .show(truncate=False)

    or use a more reliable pattern which escape all metacharacters:

        meta_chars = re.compile(r'([]$^+.*\(\)/{}\|?=><[])')
        ptn = '(^|\s+)(?:{})(\s+|$).*'.format('|'.join(meta_chars.sub(r'\\\1', x) for x in stop_words))


(45) use aggregate function to calculate running sum of an ArrayType column
  REF: https://stackoverflow.com/questions/58041497

    from pyspark.sql.functions import expr

    df = spark.createDataFrame([(e,) for e in ["aaabbbb0000ccaa", 'ttttesst']], ['x'])

    # iterate the full array, need typecast to zero value of value and also use ifnull() on calculation
    running_sum = lambda col: expr(f"""
        aggregate(
            `{col}`, 
            cast(array() as array<int>), 
            (acc,x) -> array_append(acc, coalesce(element_at(acc,-1), 0) + length(x))
        )
    """)

    df1 = df.withColumn('x1', expr(r"""regexp_extract_all(x, r'((.)\2*)',1)""")) \
        .withColumn('x3', running_sum('x1'))
    df1.show(2,0)
    +---------------+-------------------------+------------------+
    |x              |x1                       |x3                |
    +---------------+-------------------------+------------------+
    |aaabbbb0000ccaa|[aaa, bbbb, 0000, cc, aa]|[3, 7, 11, 13, 15]|
    |ttttesst       |[tttt, e, ss, t]         |[4, 5, 7, 8]      |
    +---------------+-------------------------+------------------+

   Notes: As of Spark 3.1.0, using regext_extract_all() to retrieve all matches into array, originally
          using regexp_replace + split functions to handle the same


(46) roll-up sum for an array field inside an StructType column
  REF: https://stackoverflow.com/q/65907795/9510729
  Method: use aggregate and notice how to access an array field from 
          an array of structs by `flatten(_main_object.parent_array.child_array)`
  Code:

    records = '[{"_main_object":{"parent_array":[{"child_array":[{"amount_set":{"presentment_money":{"amount":"2.73","currency_code":"USD"},"shop_money":{"amount":"2.73","currency_code":"USD"}}}],"rollup_total_shop_money_amount":"","rollup_total_presentment_money_amount":""},{"child_array":[{"amount_set":{"presentment_money":{"amount":"2.27","currency_code":"USD"},"shop_money":{"amount":"2.27","currency_code":"USD"}}}],"rollup_total_shop_money_amount":"","rollup_total_presentment_money_amount":""},{"child_array":[],"rollup_total_shop_money_amount":"","rollup_total_presentment_money_amount":""},{"child_array":[],"rollup_total_shop_money_amount":"","rollup_total_presentment_money_amount":""}]}},{"_main_object":{"parent_array":[{"child_array":[],"rollup_total_shop_money_amount":"","rollup_total_presentment_money_amount":""},{"child_array":[{"amount_set":{"presentment_money":{"amount":"2.20","currency_code":"USD"},"shop_money":{"amount":"2.20","currency_code":"USD"}}}],"rollup_total_shop_money_amount":"","rollup_total_presentment_money_amount":""},{"child_array":[],"rollup_total_shop_money_amount":"","rollup_total_presentment_money_amount":""},{"child_array":[{"amount_set":{"presentment_money":{"amount":"2.80","currency_code":"USD"},"shop_money":{"amount":"2.80","currency_code":"USD"}}}],"rollup_total_shop_money_amount":"","rollup_total_presentment_money_amount":""}]}}]'

    df = spark.read.json(sc.parallelize([records]))
    df.printSchema()
    root
     |-- _main_object: struct (nullable = true)
     |    |-- parent_array: array (nullable = true)
     |    |    |-- element: struct (containsNull = true)
     |    |    |    |-- child_array: array (nullable = true)
     |    |    |    |    |-- element: struct (containsNull = true)
     |    |    |    |    |    |-- amount_set: struct (nullable = true)
     |    |    |    |    |    |    |-- presentment_money: struct (nullable = true)
     |    |    |    |    |    |    |    |-- amount: string (nullable = true)
     |    |    |    |    |    |    |    |-- currency_code: string (nullable = true)
     |    |    |    |    |    |    |-- shop_money: struct (nullable = true)
     |    |    |    |    |    |    |    |-- amount: string (nullable = true)
     |    |    |    |    |    |    |    |-- currency_code: string (nullable = true)
     |    |-- rollup_total_presentment_money_amount: string (nullable = true)
     |    |-- rollup_total_shop_money_amount: string (nullable = true)

    df1 = df.selectExpr("""
  
       named_struct(
           "_main_object", transform(_main_object.parent_array, x -> 
                   named_struct(
                       "child_array", x.child_array,
                       "sub_total_presentment_amt", aggregate(
                               x.child_array, 
                               0D,
                               (acc,x) -> acc+float(x.amount_set.presentment_money.amount),
                               acc -> round(acc,2)
                           ),
                       "sub_total_shop_amt", aggregate(
                               x.child_array, 
                               0D, 
                               (acc,x) -> acc+float(x.amount_set.shop_money.amount),
                               acc -> round(acc,2)
                           )
                   )
               ),
           "rollup_total_presentment_money_amount", aggregate(
                   /* accessing array field inside an array of structs */
                   flatten(_main_object.parent_array.child_array), 
                   0D, 
                   (acc,x) -> acc+float(x.amount_set.presentment_money.amount),
                   acc -> round(acc,2)
               ),
           "rollup_total_shop_money_amount", aggregate(
                   flatten(_main_object.parent_array.child_array), 
                   0D, 
                   (acc,x) -> acc+float(x.amount_set.presentment_money.amount),
                   acc -> round(acc,2)
               )
       ) as new_main_object

    """)
    df1.printSchema()
    root
     |-- new_main_object: struct (nullable = false)
     |    |-- _main_object: array (nullable = true)
     |    |    |-- element: struct (containsNull = false)
     |    |    |    |-- child_array: array (nullable = true)
     |    |    |    |    |-- element: struct (containsNull = true)
     |    |    |    |    |    |-- amount_set: struct (nullable = true)
     |    |    |    |    |    |    |-- presentment_money: struct (nullable = true)
     |    |    |    |    |    |    |    |-- amount: string (nullable = true)
     |    |    |    |    |    |    |    |-- currency_code: string (nullable = true)
     |    |    |    |    |    |    |-- shop_money: struct (nullable = true)
     |    |    |    |    |    |    |    |-- amount: string (nullable = true)
     |    |    |    |    |    |    |    |-- currency_code: string (nullable = true)
     |    |    |    |-- sub_total_presentment_amt: double (nullable = true)
     |    |    |    |-- sub_total_shop_amt: double (nullable = true)
     |    |-- rollup_total_presentment_money_amount: double (nullable = true)
     |    |-- rollup_total_shop_money_amount: double (nullable = true)

    df1.show(truncate=False, vertical=True)
    -RECORD 0---------------------------------------------------------------------------------------------------------------------------------------------------
     new_main_object | [[[[[[[2.73, USD], [2.73, USD]]]], 2.73, 2.73], [[[[[2.27, USD], [2.27, USD]]]], 2.27, 2.27], [[], 0.0, 0.0], [[], 0.0, 0.0]], 5.0, 5.0] 
     -RECORD 1---------------------------------------------------------------------------------------------------------------------------------------------------
      new_main_object | [[[[], 0.0, 0.0], [[[[[2.20, USD], [2.20, USD]]]], 2.2, 2.2], [[], 0.0, 0.0], [[[[[2.80, USD], [2.80, USD]]]], 2.8, 2.8]], 5.0, 5.0]


 
