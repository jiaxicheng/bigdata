<?xml version="1.0"?>
<configuration>

  <!-- Site specific YARN configuration properties 
       -->
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value> 
  </property>

  <property>
    <name>yarn.nodemanager.address</name>
    <value>0.0.0.0:8066</value> 
  </property>

  <!-- memory set to make it work on limited resource 
  <property>
    <name>yarn.scheduler.minimum-allocation-mb</name>
    <value>512</value>
    <description>Minimum limit of memory to allocate to each container request at the Resource Manager. default is 1024MB.  </description>
  </property>
       -->

  <!-- below set up without HA
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>sgrove</value>
  </property>

  <property>
    <name>yarn.resourcemanager.address</name>
    <value>${yarn.resourcemanager.hostname}:8032</value>
  </property>

  <property>
   <name>yarn.resourcemanager.resource-tracker.address</name>
   <value>${yarn.resourcemanager.hostname}:8031</value>
  </property>

  <property>
   <name>yarn.resourcemanager.nodes.exclude-path</name>
   <value>/data/hdfs/hadoop-latest/etc/hadoop/dfs.exclude</value>
  </property>
       -->

  <!-- below for some issues with Spark 
       -->
  <property>
    <name>yarn.nodemanager.pmem-check-enabled</name>
    <value>false</value>
  </property>

  <property>
    <name>yarn.nodemanager.vmem-check-enabled</name>
    <value>false</value>
  </property>

  <!-- save logs into HDFS, not very useful
  <property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
  </property>
  -->

  <!-- for Tez  -->
  <property>
    <name>yarn.timeline-service.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>yarn.timeline-service.hostname</name>
    <value>sgrove</value>
  </property>

  <property>
    <name>yarn.timeline-service.webapp.address</name>
    <value>sgrove:8188</value>
  </property>

  <property>
    <name>yarn.timeline-service.http-cross-origin.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>yarn.resourcemanager.system-metrics-publisher.enabled</name>
    <value>true</value>
  </property>

  <!-- YARN HA configuration 
       https://hadoop.apache.org/docs/stable2/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html
       -->
  <property>
    <name>yarn.resourcemanager.ha.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>yarn.resourcemanager.cluster-id</name>
    <value>ycluster</value>
  </property>
  <property>
    <name>yarn.resourcemanager.ha.rm-ids</name>
    <value>rm1,rm2</value>
  </property>
  <property>
    <name>yarn.resourcemanager.hostname.rm1</name>
    <value>sgrove</value>
  </property>
  <property>
    <name>yarn.resourcemanager.hostname.rm2</name>
    <value>lexington</value>
  </property>
  <property>
    <name>yarn.resourcemanager.webapp.address.rm1</name>
    <value>sgrove:8088</value>
  </property>
  <property>
    <name>yarn.resourcemanager.webapp.address.rm2</name>
    <value>lexington:8088</value>
  </property>
  <property>
    <name>yarn.resourcemanager.zk-address</name>
    <value>borders:2181,lexington:2181,madison:2181</value>
  </property>

  <!-- for spark_on_hive 
       https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started
       -->
  <property>
    <name>yarn.resourcemanager.scheduler.class</name>
    <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>
  </property>

</configuration>
